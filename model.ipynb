{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, let's import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from typing import Dict\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from datasets import load_metric\n",
    "from transformers import DataCollatorWithPadding\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    EvalPrediction,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we set some model and training's parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language Model: distilbert-base-uncased and Device: cuda\n"
     ]
    }
   ],
   "source": [
    "### Model Parameters\n",
    "\n",
    "language_model_name = \"distilbert-base-uncased\"\n",
    "\n",
    "### Training Argurments\n",
    "batch_size = 32\n",
    "output_dir = \"training_dir\"\n",
    "trained = False\n",
    "\n",
    "# optim\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 0.001\n",
    "\n",
    "# training\n",
    "epochs = 1\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "print(f\"Language Model: {language_model_name} and Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'premise', 'hypothesis', 'label', 'wsd', 'srl'],\n",
      "        num_rows: 51086\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'premise', 'hypothesis', 'label', 'wsd', 'srl'],\n",
      "        num_rows: 2288\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'premise', 'hypothesis', 'label', 'wsd', 'srl'],\n",
      "        num_rows: 2287\n",
      "    })\n",
      "})\n",
      "{'id': '150448', 'premise': \"Roman Atwood . He is best known for his vlogs , where he posts updates about his life on a daily basis . His vlogging channel , `` RomanAtwoodVlogs '' , has a total of 3.3 billion views and 11.9 million subscribers . He also has another YouTube channel called `` RomanAtwood '' , where he posts pranks .\", 'hypothesis': 'Roman Atwood is a content creator.', 'label': 'ENTAILMENT', 'wsd': {'premise': [{'index': 0, 'text': 'Roman', 'pos': 'ADJ', 'lemma': 'roman', 'bnSynsetId': 'bn:00109913a', 'wnSynsetOffset': '2921569a', 'nltkSynset': 'roman.a.01'}, {'index': 1, 'text': 'Atwood', 'pos': 'PROPN', 'lemma': 'Atwood', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 2, 'text': '.', 'pos': 'PUNCT', 'lemma': '.', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 3, 'text': 'He', 'pos': 'PRON', 'lemma': 'he', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 4, 'text': 'is', 'pos': 'AUX', 'lemma': 'be', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 5, 'text': 'best', 'pos': 'ADV', 'lemma': 'well', 'bnSynsetId': 'bn:00117603r', 'wnSynsetOffset': '12779r', 'nltkSynset': 'well.r.02'}, {'index': 6, 'text': 'known', 'pos': 'VERB', 'lemma': 'know', 'bnSynsetId': 'bn:00090143v', 'wnSynsetOffset': '594337v', 'nltkSynset': 'know.v.04'}, {'index': 7, 'text': 'for', 'pos': 'ADP', 'lemma': 'for', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 8, 'text': 'his', 'pos': 'PRON', 'lemma': 'his', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 9, 'text': 'vlogs', 'pos': 'NOUN', 'lemma': 'vlog', 'bnSynsetId': 'bn:00028604n', 'wnSynsetOffset': '7007945n', 'nltkSynset': 'play.n.01'}, {'index': 10, 'text': ',', 'pos': 'PUNCT', 'lemma': ',', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 11, 'text': 'where', 'pos': 'SCONJ', 'lemma': 'where', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 12, 'text': 'he', 'pos': 'PRON', 'lemma': 'he', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 13, 'text': 'posts', 'pos': 'VERB', 'lemma': 'post', 'bnSynsetId': 'bn:00091876v', 'wnSynsetOffset': '991683v', 'nltkSynset': 'post.v.02'}, {'index': 14, 'text': 'updates', 'pos': 'NOUN', 'lemma': 'update', 'bnSynsetId': 'bn:00079238n', 'wnSynsetOffset': '6643303n', 'nltkSynset': 'update.n.01'}, {'index': 15, 'text': 'about', 'pos': 'ADP', 'lemma': 'about', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 16, 'text': 'his', 'pos': 'PRON', 'lemma': 'his', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 17, 'text': 'life', 'pos': 'NOUN', 'lemma': 'life', 'bnSynsetId': 'bn:00051045n', 'wnSynsetOffset': '13963192n', 'nltkSynset': 'life.n.01'}, {'index': 18, 'text': 'on', 'pos': 'ADP', 'lemma': 'on', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 19, 'text': 'a', 'pos': 'DET', 'lemma': 'a', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 20, 'text': 'daily', 'pos': 'ADJ', 'lemma': 'daily', 'bnSynsetId': 'bn:00100875a', 'wnSynsetOffset': '1968165a', 'nltkSynset': 'daily.s.01'}, {'index': 21, 'text': 'basis', 'pos': 'NOUN', 'lemma': 'basis', 'bnSynsetId': 'bn:00008870n', 'wnSynsetOffset': '13790912n', 'nltkSynset': 'footing.n.02'}, {'index': 22, 'text': '.', 'pos': 'PUNCT', 'lemma': '.', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 23, 'text': 'His', 'pos': 'PRON', 'lemma': 'his', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 24, 'text': 'vlogging', 'pos': 'VERB', 'lemma': 'vlogge', 'bnSynsetId': 'bn:00090000v', 'wnSynsetOffset': '672277v', 'nltkSynset': 'judge.v.01'}, {'index': 25, 'text': 'channel', 'pos': 'NOUN', 'lemma': 'channel', 'bnSynsetId': 'bn:00017686n', 'wnSynsetOffset': '3006398n', 'nltkSynset': 'channel.n.07'}, {'index': 26, 'text': ',', 'pos': 'PUNCT', 'lemma': ',', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 27, 'text': '`', 'pos': 'PUNCT', 'lemma': '`', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 28, 'text': '`', 'pos': 'PUNCT', 'lemma': '`', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 29, 'text': 'RomanAtwoodVlogs', 'pos': 'X', 'lemma': 'romanatwoodvlogs', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 30, 'text': \"''\", 'pos': 'PUNCT', 'lemma': \"''\", 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 31, 'text': ',', 'pos': 'PUNCT', 'lemma': ',', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 32, 'text': 'has', 'pos': 'AUX', 'lemma': 'have', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 33, 'text': 'a', 'pos': 'DET', 'lemma': 'a', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 34, 'text': 'total', 'pos': 'NOUN', 'lemma': 'total', 'bnSynsetId': 'bn:00002008n', 'wnSynsetOffset': '4353803n', 'nltkSynset': 'sum.n.05'}, {'index': 35, 'text': 'of', 'pos': 'ADP', 'lemma': 'of', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 36, 'text': '3.3', 'pos': 'NUM', 'lemma': '3.3', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 37, 'text': 'billion', 'pos': 'NUM', 'lemma': 'billion', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 38, 'text': 'views', 'pos': 'NOUN', 'lemma': 'view', 'bnSynsetId': 'bn:00071511n', 'wnSynsetOffset': '881649n', 'nltkSynset': 'view.n.03'}, {'index': 39, 'text': 'and', 'pos': 'CCONJ', 'lemma': 'and', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 40, 'text': '11.9', 'pos': 'NUM', 'lemma': '11.9', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 41, 'text': 'million', 'pos': 'NUM', 'lemma': 'million', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 42, 'text': 'subscribers', 'pos': 'NOUN', 'lemma': 'subscriber', 'bnSynsetId': 'bn:00066366n', 'wnSynsetOffset': '10670483n', 'nltkSynset': 'subscriber.n.02'}, {'index': 43, 'text': '.', 'pos': 'PUNCT', 'lemma': '.', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 44, 'text': 'He', 'pos': 'PRON', 'lemma': 'he', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 45, 'text': 'also', 'pos': 'ADV', 'lemma': 'also', 'bnSynsetId': 'bn:00114246r', 'wnSynsetOffset': '47534r', 'nltkSynset': 'besides.r.02'}, {'index': 46, 'text': 'has', 'pos': 'AUX', 'lemma': 'have', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 47, 'text': 'another', 'pos': 'DET', 'lemma': 'another', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 48, 'text': 'YouTube', 'pos': 'PROPN', 'lemma': 'YouTube', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 49, 'text': 'channel', 'pos': 'NOUN', 'lemma': 'channel', 'bnSynsetId': 'bn:00015144n', 'wnSynsetOffset': '5250659n', 'nltkSynset': 'duct.n.01'}, {'index': 50, 'text': 'called', 'pos': 'VERB', 'lemma': 'call', 'bnSynsetId': 'bn:00084385v', 'wnSynsetOffset': '1028748v', 'nltkSynset': 'name.v.01'}, {'index': 51, 'text': '`', 'pos': 'PUNCT', 'lemma': '`', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 52, 'text': '`', 'pos': 'PUNCT', 'lemma': '`', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 53, 'text': 'RomanAtwood', 'pos': 'PROPN', 'lemma': 'RomanAtwood', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 54, 'text': \"''\", 'pos': 'PUNCT', 'lemma': \"''\", 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 55, 'text': ',', 'pos': 'PUNCT', 'lemma': ',', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 56, 'text': 'where', 'pos': 'SCONJ', 'lemma': 'where', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 57, 'text': 'he', 'pos': 'PRON', 'lemma': 'he', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 58, 'text': 'posts', 'pos': 'VERB', 'lemma': 'post', 'bnSynsetId': 'bn:00091876v', 'wnSynsetOffset': '991683v', 'nltkSynset': 'post.v.02'}, {'index': 59, 'text': 'pranks', 'pos': 'NOUN', 'lemma': 'prank', 'bnSynsetId': 'bn:00004630n', 'wnSynsetOffset': '427580n', 'nltkSynset': 'antic.n.01'}, {'index': 60, 'text': '.', 'pos': 'PUNCT', 'lemma': '.', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}], 'hypothesis': [{'index': 0, 'text': 'Roman', 'pos': 'PROPN', 'lemma': 'Roman', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 1, 'text': 'Atwood', 'pos': 'PROPN', 'lemma': 'Atwood', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 2, 'text': 'is', 'pos': 'AUX', 'lemma': 'be', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 3, 'text': 'a', 'pos': 'DET', 'lemma': 'a', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 4, 'text': 'content', 'pos': 'ADJ', 'lemma': 'content', 'bnSynsetId': 'bn:00100364a', 'wnSynsetOffset': '588797a', 'nltkSynset': 'contented.a.01'}, {'index': 5, 'text': 'creator', 'pos': 'NOUN', 'lemma': 'creator', 'bnSynsetId': 'bn:00023660n', 'wnSynsetOffset': '9614315n', 'nltkSynset': 'creator.n.02'}, {'index': 6, 'text': '.', 'pos': 'PUNCT', 'lemma': '.', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}]}, 'srl': {'premise': {'tokens': [{'index': 0, 'rawText': 'Roman'}, {'index': 1, 'rawText': 'Atwood'}, {'index': 2, 'rawText': '.'}, {'index': 3, 'rawText': 'He'}, {'index': 4, 'rawText': 'is'}, {'index': 5, 'rawText': 'best'}, {'index': 6, 'rawText': 'known'}, {'index': 7, 'rawText': 'for'}, {'index': 8, 'rawText': 'his'}, {'index': 9, 'rawText': 'vlogs'}, {'index': 10, 'rawText': ','}, {'index': 11, 'rawText': 'where'}, {'index': 12, 'rawText': 'he'}, {'index': 13, 'rawText': 'posts'}, {'index': 14, 'rawText': 'updates'}, {'index': 15, 'rawText': 'about'}, {'index': 16, 'rawText': 'his'}, {'index': 17, 'rawText': 'life'}, {'index': 18, 'rawText': 'on'}, {'index': 19, 'rawText': 'a'}, {'index': 20, 'rawText': 'daily'}, {'index': 21, 'rawText': 'basis'}, {'index': 22, 'rawText': '.'}, {'index': 23, 'rawText': 'His'}, {'index': 24, 'rawText': 'vlogging'}, {'index': 25, 'rawText': 'channel'}, {'index': 26, 'rawText': ','}, {'index': 27, 'rawText': '`'}, {'index': 28, 'rawText': '`'}, {'index': 29, 'rawText': 'RomanAtwoodVlogs'}, {'index': 30, 'rawText': \"''\"}, {'index': 31, 'rawText': ','}, {'index': 32, 'rawText': 'has'}, {'index': 33, 'rawText': 'a'}, {'index': 34, 'rawText': 'total'}, {'index': 35, 'rawText': 'of'}, {'index': 36, 'rawText': '3.3'}, {'index': 37, 'rawText': 'billion'}, {'index': 38, 'rawText': 'views'}, {'index': 39, 'rawText': 'and'}, {'index': 40, 'rawText': '11.9'}, {'index': 41, 'rawText': 'million'}, {'index': 42, 'rawText': 'subscribers'}, {'index': 43, 'rawText': '.'}, {'index': 44, 'rawText': 'He'}, {'index': 45, 'rawText': 'also'}, {'index': 46, 'rawText': 'has'}, {'index': 47, 'rawText': 'another'}, {'index': 48, 'rawText': 'YouTube'}, {'index': 49, 'rawText': 'channel'}, {'index': 50, 'rawText': 'called'}, {'index': 51, 'rawText': '`'}, {'index': 52, 'rawText': '`'}, {'index': 53, 'rawText': 'RomanAtwood'}, {'index': 54, 'rawText': \"''\"}, {'index': 55, 'rawText': ','}, {'index': 56, 'rawText': 'where'}, {'index': 57, 'rawText': 'he'}, {'index': 58, 'rawText': 'posts'}, {'index': 59, 'rawText': 'pranks'}, {'index': 60, 'rawText': '.'}], 'annotations': [{'tokenIndex': 4, 'verbatlas': {'frameName': 'COPULA', 'roles': [{'role': 'Theme', 'score': 1.0, 'span': [3, 4]}, {'role': 'Attribute', 'score': 1.0, 'span': [5, 22]}]}, 'englishPropbank': {'frameName': 'be.01', 'roles': [{'role': 'ARG1', 'score': 1.0, 'span': [3, 4]}, {'role': 'ARG2', 'score': 1.0, 'span': [5, 22]}]}}, {'tokenIndex': 6, 'verbatlas': {'frameName': 'KNOW', 'roles': [{'role': 'Theme', 'score': 1.0, 'span': [3, 4]}, {'role': 'Attribute', 'score': 1.0, 'span': [5, 6]}, {'role': 'Topic', 'score': 1.0, 'span': [7, 22]}]}, 'englishPropbank': {'frameName': 'know.01', 'roles': [{'role': 'ARG1', 'score': 1.0, 'span': [3, 4]}, {'role': 'ARGM-MNR', 'score': 1.0, 'span': [5, 6]}, {'role': 'ARG2', 'score': 1.0, 'span': [7, 22]}]}}, {'tokenIndex': 13, 'verbatlas': {'frameName': 'RECORD', 'roles': [{'role': 'Location', 'score': 1.0, 'span': [8, 10]}, {'role': 'Agent', 'score': 1.0, 'span': [12, 13]}, {'role': 'Theme', 'score': 1.0, 'span': [14, 18]}, {'role': 'Time', 'score': 1.0, 'span': [18, 22]}]}, 'englishPropbank': {'frameName': 'post.01', 'roles': [{'role': 'ARGM-LOC', 'score': 1.0, 'span': [8, 10]}, {'role': 'R-ARGM-LOC', 'score': 1.0, 'span': [11, 12]}, {'role': 'ARG0', 'score': 1.0, 'span': [12, 13]}, {'role': 'ARG1', 'score': 1.0, 'span': [14, 18]}, {'role': 'ARGM-TMP', 'score': 1.0, 'span': [18, 22]}]}}, {'tokenIndex': 32, 'verbatlas': {'frameName': 'EXIST-WITH-FEATURE', 'roles': [{'role': 'Theme', 'score': 1.0, 'span': [23, 32]}, {'role': 'Attribute', 'score': 1.0, 'span': [33, 43]}]}, 'englishPropbank': {'frameName': 'have.03', 'roles': [{'role': 'ARG0', 'score': 1.0, 'span': [23, 32]}, {'role': 'ARG1', 'score': 1.0, 'span': [33, 43]}]}}, {'tokenIndex': 46, 'verbatlas': {'frameName': 'EXIST-WITH-FEATURE', 'roles': [{'role': 'Theme', 'score': 1.0, 'span': [44, 45]}, {'role': 'Attribute', 'score': 1.0, 'span': [47, 60]}]}, 'englishPropbank': {'frameName': 'have.03', 'roles': [{'role': 'ARG0', 'score': 1.0, 'span': [44, 45]}, {'role': 'ARGM-DIS', 'score': 1.0, 'span': [45, 46]}, {'role': 'ARG1', 'score': 1.0, 'span': [47, 60]}]}}, {'tokenIndex': 50, 'verbatlas': {'frameName': 'NAME', 'roles': [{'role': 'Theme', 'score': 1.0, 'span': [47, 50]}, {'role': 'Attribute', 'score': 1.0, 'span': [51, 55]}]}, 'englishPropbank': {'frameName': 'call.01', 'roles': [{'role': 'ARG1', 'score': 1.0, 'span': [47, 50]}, {'role': 'ARG2', 'score': 1.0, 'span': [51, 55]}]}}, {'tokenIndex': 58, 'verbatlas': {'frameName': 'RECORD', 'roles': [{'role': 'Location', 'score': 1.0, 'span': [47, 55]}, {'role': 'Agent', 'score': 1.0, 'span': [57, 58]}, {'role': 'Theme', 'score': 1.0, 'span': [59, 60]}]}, 'englishPropbank': {'frameName': 'post.01', 'roles': [{'role': 'ARGM-LOC', 'score': 1.0, 'span': [47, 55]}, {'role': 'R-ARGM-LOC', 'score': 1.0, 'span': [56, 57]}, {'role': 'ARG0', 'score': 1.0, 'span': [57, 58]}, {'role': 'ARG1', 'score': 1.0, 'span': [59, 60]}]}}]}, 'hypothesis': {'tokens': [{'index': 0, 'rawText': 'Roman'}, {'index': 1, 'rawText': 'Atwood'}, {'index': 2, 'rawText': 'is'}, {'index': 3, 'rawText': 'a'}, {'index': 4, 'rawText': 'content'}, {'index': 5, 'rawText': 'creator'}, {'index': 6, 'rawText': '.'}], 'annotations': [{'tokenIndex': 2, 'verbatlas': {'frameName': 'COPULA', 'roles': [{'role': 'Theme', 'score': 1.0, 'span': [0, 2]}, {'role': 'Attribute', 'score': 1.0, 'span': [3, 6]}]}, 'englishPropbank': {'frameName': 'be.01', 'roles': [{'role': 'ARG1', 'score': 1.0, 'span': [0, 2]}, {'role': 'ARG2', 'score': 1.0, 'span': [3, 6]}]}}]}}}\n",
      "Label of the first sentence: ENTAILMENT\n",
      "['ENTAILMENT', 'NEUTRAL', 'CONTRADICTION']\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "dataset = load_dataset(\"tommasobonomo/sem_augmented_fever_nli\")\n",
    "\n",
    "# Let's see an example...\n",
    "print(dataset)\n",
    "print(dataset['train'][0])\n",
    "print(\"Label of the first sentence:\", dataset['train'][0]['label']) \n",
    "\n",
    "# Take a look at the labels\n",
    "all_labels = []\n",
    "for label in dataset['train'].unique(\"label\"):\n",
    "    all_labels.append(label)\n",
    "\n",
    "print(all_labels) ## ['ENTAILMENT', 'NEUTRAL', 'CONTRADICTION'] == ['SUPPORTS', 'NOT ENOUGH INFO', 'REFUTES']\n",
    "\n",
    "# Label mapping\n",
    "\n",
    "label_map = {\n",
    "    'ENTAILMENT': 0,\n",
    "    'NEUTRAL': 1,\n",
    "    'CONTRADICTION': 2\n",
    "}\n",
    "\n",
    "def convert_labels(example):\n",
    "    example['label'] = label_map[example['label']]\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the metrics\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "   load_accuracy = load_metric(\"accuracy\")\n",
    "   load_f1 = load_metric(\"f1\")\n",
    "\n",
    "   logits, labels = eval_pred\n",
    "   predictions = np.argmax(logits, axis=-1)\n",
    "   accuracy = load_accuracy.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "   f1 = load_f1.compute(predictions=predictions, references=labels, average='macro')[\"f1\"]\n",
    "   return {\"accuracy\": accuracy, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the fine-tuned model from the saved directory...\n"
     ]
    }
   ],
   "source": [
    "## Initialize the model\n",
    "\n",
    "if os.path.exists(output_dir) and os.path.isdir(output_dir):\n",
    "    print(\"Loading the fine-tuned model from the saved directory...\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(output_dir).to(device)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
    "    trained = True\n",
    "else:\n",
    "    print(\"Training the model from scratch...\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(language_model_name, \n",
    "                                                                   ignore_mismatched_sizes=True,\n",
    "                                                                   output_attentions=False, output_hidden_states=False,\n",
    "                                                                   num_labels=3).to(device)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(language_model_name)\n",
    "    trained = False\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"premise\"], examples[\"hypothesis\"], padding=True, truncation=True)\n",
    "\n",
    "# Tokenize the dataset\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.map(convert_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'premise', 'hypothesis', 'label', 'wsd', 'srl', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 51086\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'premise', 'hypothesis', 'label', 'wsd', 'srl', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 2288\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'premise', 'hypothesis', 'label', 'wsd', 'srl', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 2287\n",
      "    })\n",
      "})\n",
      "First example premise: Roman Atwood . He is best known for his vlogs , where he posts updates about his life on a daily basis . His vlogging channel , `` RomanAtwoodVlogs '' , has a total of 3.3 billion views and 11.9 million subscribers . He also has another YouTube channel called `` RomanAtwood '' , where he posts pranks . and hypothesis: Roman Atwood is a content creator.\n",
      "Tokenized input:  [101, 3142, 2012, 3702, 1012, 2002, 2003, 2190, 2124, 2005, 2010, 1058, 21197, 2015, 1010, 2073, 2002, 8466, 14409, 2055, 2010, 2166, 2006, 1037, 3679, 3978, 1012, 2010, 1058, 21197, 4726, 3149, 1010, 1036, 1036, 3142, 4017, 3702, 2615, 21197, 2015, 1005, 1005, 1010, 2038, 1037, 2561, 1997, 1017, 1012, 1017, 4551, 5328, 1998, 2340, 1012, 1023, 2454, 17073, 1012, 2002, 2036, 2038, 2178, 7858, 3149, 2170, 1036, 1036, 3142, 4017, 3702, 1005, 1005, 1010, 2073, 2002, 8466, 26418, 2015, 1012, 102, 3142, 2012, 3702, 2003, 1037, 4180, 8543, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Label of the first sentence: 0\n",
      "[0, 1, 2]\n",
      "Decoded input:  [CLS] roman atwood. he is best known for his vlogs, where he posts updates about his life on a daily basis. his vlogging channel, ` ` romanatwoodvlogs'', has a total of 3. 3 billion views and 11. 9 million subscribers. he also has another youtube channel called ` ` romanatwood'', where he posts pranks. [SEP] roman atwood is a content creator. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "# Let's see the tokenized dataset and the first example\n",
    "\n",
    "print(tokenized_datasets)\n",
    "print(f\"First example premise: {tokenized_datasets['train'][0]['premise']} and hypothesis: {tokenized_datasets['train'][0]['hypothesis']}\")\n",
    "print(\"Tokenized input: \", tokenized_datasets['train'][0]['input_ids'])\n",
    "\n",
    "# Print the labels\n",
    "print(\"Label of the first sentence:\", tokenized_datasets['train'][0]['label'])\n",
    "all_labels = []\n",
    "for label in tokenized_datasets['train'].unique(\"label\"):\n",
    "    all_labels.append(label)\n",
    "print(all_labels)\n",
    "\n",
    "# Test the corrispondence by decoding the input_ids\n",
    "print(\"Decoded input: \", tokenizer.decode(tokenized_datasets['train'][0]['input_ids']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,                            # output directory [Mandatory]\n",
    "    num_train_epochs=epochs,                          # total number of training epochs\n",
    "    per_device_train_batch_size=batch_size,           # batch size per device during training\n",
    "    per_device_eval_batch_size=batch_size,            # batch size for evaluation\n",
    "    warmup_steps=500,                                 # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=weight_decay,                        # strength of weight decay\n",
    "    save_strategy=\"no\",\n",
    "    learning_rate=learning_rate                       # learning rate\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,                                       # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=training_args,                                # training arguments, defined above\n",
    "    train_dataset=tokenized_datasets[\"train\"],         # training dataset\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],     # evaluation dataset\n",
    "    tokenizer=tokenizer,                               # the tokenizer\n",
    "    data_collator=data_collator,                       # data collator\n",
    "    compute_metrics=compute_metrics                    # the callback that computes metrics of interest\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model already trained.\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "if not trained:\n",
    "    print(\"Training the model...\")\n",
    "    trainer.train()\n",
    "else:\n",
    "    print(\"Model already trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model already saved.\n"
     ]
    }
   ],
   "source": [
    "if not trained:\n",
    "    print(\"Saving the model...\")\n",
    "    trainer.save_model(output_dir)\n",
    "    trained = True\n",
    "else:\n",
    "    print(\"Model already saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d851793e09614f50a452fbcb8299a9da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mattia Maffo\\AppData\\Local\\Temp\\ipykernel_19128\\1165214118.py:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  load_accuracy = load_metric(\"accuracy\")\n",
      "c:\\Users\\Mattia Maffo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Mattia Maffo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\load.py:759: FutureWarning: The repository for f1 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/f1/f1.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results for the initial test dataset:  {'eval_loss': 0.7723000049591064, 'eval_accuracy': 0.7022299956274596, 'eval_f1': 0.686098316835566, 'eval_runtime': 20.2788, 'eval_samples_per_second': 112.778, 'eval_steps_per_second': 3.551}\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "if trained:\n",
    "    print(\"Evaluating the model...\")\n",
    "    metrics = trainer.evaluate(eval_dataset=tokenized_datasets[\"test\"])\n",
    "    # print the metrics\n",
    "    print(\"Evaluation results for the initial test dataset: \", metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['part', 'cid', 'premise', 'hypothesis', 'label'],\n",
      "        num_rows: 337\n",
      "    })\n",
      "})\n",
      "{'part': 'manual_adversarial', 'cid': 58846, 'premise': 'Johnny Galecki . He is known for playing David Healy in the ABC sitcom Roseanne from 1992 -- 1997 and Dr. Leonard Hofstadter in the CBS sitcom The Big Bang Theory since 2007 .', 'hypothesis': 'The number of sitcoms from France in which Johnny Galecki has played a character is greater or equal to 2', 'label': 'NEUTRAL'}\n"
     ]
    }
   ],
   "source": [
    "# Now let's do evaluation on the Adversarial Fever Dataset.\n",
    "# Let's start loading the new dataset.\n",
    "\n",
    "adversarial_dataset = load_dataset(\"iperbole/adversarial_fever_nli\")\n",
    "\n",
    "# Let's see an example...\n",
    "print(adversarial_dataset)\n",
    "print(adversarial_dataset['test'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['part', 'cid', 'premise', 'hypothesis', 'label', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 337\n",
      "    })\n",
      "})\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Tokenize and convert the labels\n",
    "tokenized_adversarial = adversarial_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_adversarial = tokenized_adversarial.map(convert_labels)\n",
    "\n",
    "print(tokenized_adversarial)\n",
    "print(tokenized_adversarial['test'][0]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "184fdc24e75a4715a827963640229f2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mattia Maffo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Mattia Maffo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\load.py:759: FutureWarning: The repository for f1 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/f1/f1.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results for the Adversarial Fever Dataset:  {'eval_loss': 1.291935682296753, 'eval_accuracy': 0.5014836795252225, 'eval_f1': 0.5038331002848744, 'eval_runtime': 3.6556, 'eval_samples_per_second': 92.188, 'eval_steps_per_second': 3.009}\n"
     ]
    }
   ],
   "source": [
    "# Let's do the evaluation\n",
    "eval_results = trainer.evaluate(eval_dataset= tokenized_adversarial[\"test\"])\n",
    "print(\"Evaluation results for the Adversarial Fever Dataset: \", eval_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My augmented dataset: \n",
      " DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'premise', 'hypothesis', 'label'],\n",
      "        num_rows: 61086\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'premise', 'hypothesis', 'label'],\n",
      "        num_rows: 7288\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'premise', 'hypothesis', 'label'],\n",
      "        num_rows: 2287\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Now let's work on another task: we are going to train the model on the dataset composed by the concatenation of the initial training Fever Dataset and my augmented dataset.\n",
    "# Let's start loading the new dataset.\n",
    "from datasets import DatasetDict\n",
    "\n",
    "\n",
    "augmented_dataset = DatasetDict.load_from_disk('dataset_dict')\n",
    "# Drop the 'wsd' and 'srl' features. -> Labels already converted.\n",
    "augmented_dataset['test'] = augmented_dataset['test'].remove_columns(['wsd', 'srl'])\n",
    "print(\"My augmented dataset: \\n\", augmented_dataset)\n",
    "\n",
    "# We use the same training parameters, tokenizer and model as before. -> different training dir.\n",
    "output_dir_augmented = \"training_dir_augmented\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the fine-tuned model from the saved directory...\n"
     ]
    }
   ],
   "source": [
    "## Initialize the model\n",
    "\n",
    "if os.path.exists(output_dir_augmented) and os.path.isdir(output_dir_augmented):\n",
    "    print(\"Loading the fine-tuned model from the saved directory...\")\n",
    "    model_aug = AutoModelForSequenceClassification.from_pretrained(output_dir_augmented).to(device)\n",
    "    tokenizer_aug = AutoTokenizer.from_pretrained(output_dir_augmented)\n",
    "    trained = True\n",
    "else:\n",
    "    print(\"Training the new model from scratch...\")\n",
    "    model_aug = AutoModelForSequenceClassification.from_pretrained(language_model_name, \n",
    "                                                                   ignore_mismatched_sizes=True,\n",
    "                                                                   output_attentions=False, output_hidden_states=False,\n",
    "                                                                   num_labels=3).to(device)\n",
    "    tokenizer_aug = AutoTokenizer.from_pretrained(language_model_name)\n",
    "    trained = False\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer_aug)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer_aug(examples[\"premise\"], examples[\"hypothesis\"], padding=True, truncation=True)\n",
    "\n",
    "# Tokenize the dataset\n",
    "tokenized_augmented_dataset = augmented_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized input:  [101, 3142, 2012, 3702, 1012, 2002, 2003, 2190, 2124, 2005, 2010, 1058, 21197, 2015, 1010, 2073, 2002, 8466, 14409, 2055, 2010, 2166, 2006, 1037, 3679, 3978, 1012, 2010, 1058, 21197, 4726, 3149, 1010, 1036, 1036, 3142, 4017, 3702, 2615, 21197, 2015, 1005, 1005, 1010, 2038, 1037, 2561, 1997, 1017, 1012, 1017, 4551, 5328, 1998, 2340, 1012, 1023, 2454, 17073, 1012, 2002, 2036, 2038, 2178, 7858, 3149, 2170, 1036, 1036, 3142, 4017, 3702, 1005, 1005, 1010, 2073, 2002, 8466, 26418, 2015, 1012, 102, 3142, 2012, 3702, 2003, 1037, 4180, 8543, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Let's check if the tokenization is correct\n",
    "print(\"Tokenized input: \", tokenized_augmented_dataset['train'][0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(output_dir_augmented, exist_ok=True)\n",
    "\n",
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir_augmented,                  # output directory [Mandatory]\n",
    "    num_train_epochs=epochs,                          # total number of training epochs\n",
    "    per_device_train_batch_size=batch_size,           # batch size per device during training\n",
    "    per_device_eval_batch_size=batch_size,                    # batch size for evaluation\n",
    "    warmup_steps=500,                                 # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=weight_decay,                        # strength of weight decay\n",
    "    save_strategy=\"no\",\n",
    "    learning_rate=learning_rate                       # learning rate\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer_aug = Trainer(\n",
    "    model=model_aug,                                            # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=training_args,                                         # training arguments, defined above\n",
    "    train_dataset=tokenized_augmented_dataset[\"train\"],         # training dataset\n",
    "    eval_dataset=tokenized_augmented_dataset[\"validation\"],     # evaluation dataset\n",
    "    tokenizer=tokenizer_aug,                                    # the tokenizer\n",
    "    data_collator=data_collator,                                # data collator\n",
    "    compute_metrics=compute_metrics                             # the callback that computes metrics of interest\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model already trained.\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "if not trained:\n",
    "    print(\"Training the model...\")\n",
    "    trainer_aug.train()\n",
    "else:\n",
    "    print(\"Model already trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model already saved.\n"
     ]
    }
   ],
   "source": [
    "if not trained:\n",
    "    print(\"Saving the model...\")\n",
    "    trainer_aug.save_model(output_dir_augmented)\n",
    "    trained = True\n",
    "else:\n",
    "    print(\"Model already saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faa31ecdf0fd498480ffb75433895791",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mattia Maffo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Mattia Maffo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\load.py:759: FutureWarning: The repository for f1 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/f1/f1.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results for the initial test dataset:  {'eval_loss': 0.8025291562080383, 'eval_accuracy': 0.7092260603410582, 'eval_f1': 0.692296233672235, 'eval_runtime': 19.431, 'eval_samples_per_second': 117.699, 'eval_steps_per_second': 3.705}\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "if trained:\n",
    "    print(\"Evaluating the model...\")\n",
    "    metrics = trainer_aug.evaluate(eval_dataset=tokenized_augmented_dataset[\"test\"])\n",
    "    # print the metrics\n",
    "    print(\"Evaluation results for the initial test dataset: \", metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62240dbfb219402892f0495f90eb53fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mattia Maffo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Mattia Maffo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\load.py:759: FutureWarning: The repository for f1 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/f1/f1.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results for the Adversarial Fever Dataset:  {'eval_loss': 1.3428587913513184, 'eval_accuracy': 0.5133531157270029, 'eval_f1': 0.5140298545393321, 'eval_runtime': 3.6459, 'eval_samples_per_second': 92.433, 'eval_steps_per_second': 3.017}\n"
     ]
    }
   ],
   "source": [
    "#Finally let's do evaluation on the Adversarial Fever Dataset.\n",
    "# Let's do the evaluation\n",
    "new_eval_results = trainer_aug.evaluate(eval_dataset= tokenized_adversarial[\"test\"])\n",
    "print(\"Evaluation results for the Adversarial Fever Dataset: \", new_eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
